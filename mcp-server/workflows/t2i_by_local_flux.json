{
  "3": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "6",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "4": {
    "inputs": {
      "guidance": 3.5,
      "conditioning": [
        "8",
        0
      ]
    },
    "class_type": "FluxGuidance",
    "_meta": {
      "title": "FluxGuidance"
    }
  },
  "5": {
    "inputs": {
      "seed": 857483279882614,
      "steps": 8,
      "cfg": 1.5,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 1,
      "model": [
        "9",
        0
      ],
      "positive": [
        "4",
        0
      ],
      "negative": [
        "14",
        0
      ],
      "latent_image": [
        "7",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "6": {
    "inputs": {
      "samples": [
        "5",
        0
      ],
      "vae": [
        "18",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "7": {
    "inputs": {
      "width": [
        "10",
        0
      ],
      "height": [
        "11",
        0
      ],
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "8": {
    "inputs": {
      "text": [
        "12",
        0
      ],
      "clip": [
        "17",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode"
    }
  },
  "9": {
    "inputs": {
      "lora_name": "FLUX.1-Turbo-Alpha.safetensors",
      "strength_model": 1.0000000000000002,
      "model": [
        "15",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "10": {
    "inputs": {
      "value": 512
    },
    "class_type": "easy int",
    "_meta": {
      "title": "$width.value:The width of the image"
    }
  },
  "11": {
    "inputs": {
      "value": 512
    },
    "class_type": "easy int",
    "_meta": {
      "title": "$height.value:The height of the image"
    }
  },
  "12": {
    "inputs": {
      "value": "a dog"
    },
    "class_type": "PrimitiveStringMultiline",
    "_meta": {
      "title": "$prompt.value!:The prompt to generate the image, must be english"
    }
  },
  "13": {
    "inputs": {
      "value": "Generate high-quality images from text prompts using local FLUX 1.1 model.\n    \n    Creates completely new images with exceptional detail, style diversity, and prompt adherence.\n    The model excels at photorealistic scenes, artistic styles, and complex compositions.\n    \n    Prompt writing tips for best results:\n    - Be detailed and specific: include colors, mood, lighting, and composition\n    - Use natural language and full sentences rather than keywords\n    - For photos: mention camera type, settings (e.g., \"shot on DSLR, f/2.8, golden hour\")\n    - For portraits: describe features, expressions, clothing, and background\n    - For scenes: specify foreground, middle ground, and background elements\n    \n    Excellent prompt examples:\n    - \"birthday, girl selfie with bright smile and colorful balloons\"\n    - \"Close-up portrait of a child with bright vivid emotions, sparkling eyes full of joy, sunlight dancing on rosy cheeks\"\n    - \"Serene lake reflecting dense forest during golden hour, shot on DSLR with wide-angle lens, f/8, perfect symmetry\"\n    - \"Vintage travel poster for Paris, Eiffel Tower silhouette in warm sunset colors, 'PARIS' in golden Art Deco font\"\n    - \"Ethereal dragon with neon lightning crystal on head, glowing blue eyes, majestic wings spread wide\""
    },
    "class_type": "PrimitiveStringMultiline",
    "_meta": {
      "title": "MCP"
    }
  },
  "14": {
    "inputs": {
      "conditioning": [
        "8",
        0
      ]
    },
    "class_type": "ConditioningZeroOut",
    "_meta": {
      "title": "ConditioningZeroOut"
    }
  },
  "15": {
    "inputs": {
      "unet_name": "flux1-dev.safetensors",
      "weight_dtype": "fp8_e4m3fn"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "17": {
    "inputs": {
      "clip_name1": "clip_l.safetensors",
      "clip_name2": "t5xxl_fp16.safetensors",
      "type": "flux",
      "device": "default"
    },
    "class_type": "DualCLIPLoader",
    "_meta": {
      "title": "DualCLIPLoader"
    }
  },
  "18": {
    "inputs": {
      "vae_name": "ae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  }
}
