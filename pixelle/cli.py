# Copyright (C) 2025 AIDC-AI
# This project is licensed under the MIT License (SPDX-License-identifier: MIT).

import typer
import questionary
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from pathlib import Path
import socket
from typing import Dict, List, Optional
import requests
from urllib.parse import urljoin

import psutil

from pixelle.settings import settings

app = typer.Typer(add_completion=False, help="ğŸ¨ Pixelle MCP - å°†ComfyUIå·¥ä½œæµè½¬æ¢ä¸ºMCPå·¥å…·")
console = Console()


def main():
    """ğŸ¨ Pixelle MCP ç»Ÿä¸€å…¥å£ç‚¹ - æ™ºèƒ½åˆ¤æ–­ç”¨æˆ·æ„å›¾"""
    
    # æ˜¾ç¤ºæ¬¢è¿ç•Œé¢
    show_welcome()
    
    # æ£€æµ‹é…ç½®çŠ¶æ€
    config_status = detect_config_status()
    
    if config_status == "first_time":
        # é¦–æ¬¡ä½¿ç”¨ï¼šå®Œæ•´é…ç½®å‘å¯¼ + å¯åŠ¨
        console.print("\nğŸ¯ [bold blue]æ£€æµ‹åˆ°è¿™æ˜¯æ‚¨é¦–æ¬¡ä½¿ç”¨ Pixelle MCPï¼[/bold blue]")
        console.print("æˆ‘ä»¬å°†å¼•å¯¼æ‚¨å®Œæˆç®€å•çš„é…ç½®è¿‡ç¨‹...\n")
        
        if questionary.confirm("å¼€å§‹é…ç½®å‘å¯¼ï¼Ÿ", default=True, instruction="(Y/n)").ask():
            run_full_setup_wizard()
        else:
            console.print("âŒ é…ç½®å·²å–æ¶ˆã€‚æ‚¨å¯ä»¥éšæ—¶å†æ¬¡è¿è¡Œ [bold]pixelle[/bold] æ¥é…ç½®ã€‚")
            return
            
    elif config_status == "incomplete":
        # é…ç½®ä¸å®Œæ•´ï¼šå¼•å¯¼ç”¨æˆ·å¤„ç†
        console.print("\nâš ï¸  [bold yellow]æ£€æµ‹åˆ°é…ç½®æ–‡ä»¶å­˜åœ¨ä½†ä¸å®Œæ•´[/bold yellow]")
        console.print("ğŸ’¡ å»ºè®®é‡æ–°å¼•å¯¼é…ç½®æˆ–æ‰‹åŠ¨ç¼–è¾‘é…ç½®æ–‡ä»¶")
        show_main_menu()
        
    else:
        # å·²å®Œæ•´é…ç½®ï¼šæ˜¾ç¤ºä¸»èœå•
        show_main_menu()


def show_welcome():
    """æ˜¾ç¤ºæ¬¢è¿ç•Œé¢"""
    welcome_text = """
ğŸ¨ [bold blue]Pixelle MCP 2.0[/bold blue]
å°†ComfyUIå·¥ä½œæµè½¬æ¢ä¸ºMCPå·¥å…·çš„æç®€è§£å†³æ–¹æ¡ˆ

âœ¨ 30ç§’ä»é›¶åˆ°AIåŠ©æ‰‹
ğŸ”§ é›¶ä»£ç å°†å·¥ä½œæµè½¬ä¸ºMCPå·¥å…·  
ğŸŒ æ”¯æŒCursorã€Claude Desktopç­‰MCPå®¢æˆ·ç«¯
ğŸ¤– æ”¯æŒå¤šç§ä¸»æµLLMï¼ˆOpenAIã€Ollamaã€Geminiç­‰ï¼‰
"""
    
    console.print(Panel(
        welcome_text,
        title="Welcome to Pixelle MCP",
        border_style="blue",
        padding=(1, 2)
    ))


def detect_config_status() -> str:
    """æ£€æµ‹å½“å‰é…ç½®çŠ¶æ€"""
    env_file = Path(".env")
    
    if not env_file.exists():
        return "first_time"
    
    # æ£€æŸ¥å¿…è¦çš„é…ç½®é¡¹
    required_configs = [
        "COMFYUI_BASE_URL",
        # è‡³å°‘è¦æœ‰ä¸€ä¸ªLLMé…ç½®
        ("OPENAI_API_KEY", "OLLAMA_BASE_URL", "GEMINI_API_KEY", "DEEPSEEK_API_KEY", "CLAUDE_API_KEY", "QWEN_API_KEY")
    ]
    
    env_vars = {}
    with open(env_file, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith('#') and '=' in line:
                key, value = line.split('=', 1)
                env_vars[key.strip()] = value.strip().strip('"\'')
    
    # æ£€æŸ¥ComfyUIé…ç½®
    if "COMFYUI_BASE_URL" not in env_vars or not env_vars["COMFYUI_BASE_URL"]:
        return "incomplete"
    
    # æ£€æŸ¥æ˜¯å¦è‡³å°‘æœ‰ä¸€ä¸ªLLMé…ç½®
    llm_configs = required_configs[1]
    has_llm = any(key in env_vars and env_vars[key] for key in llm_configs)
    if not has_llm:
        return "incomplete"
    
    return "complete"


def run_full_setup_wizard():
    """è¿è¡Œå®Œæ•´çš„é…ç½®å‘å¯¼"""
    console.print("\nğŸš€ [bold]å¼€å§‹ Pixelle MCP é…ç½®å‘å¯¼[/bold]\n")
    
    try:
        # Step 1: ComfyUIé…ç½®
        comfyui_config = setup_comfyui()
        if not comfyui_config:
            console.print("âš ï¸  ComfyUIé…ç½®è·³è¿‡ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®ç»§ç»­")
            comfyui_config = {"url": "http://localhost:8188"}  # ä½¿ç”¨é»˜è®¤å€¼
        
        # Step 2: LLMé…ç½®ï¼ˆå¯é…ç½®å¤šä¸ªï¼‰
        llm_configs = setup_multiple_llm_providers()
        if not llm_configs:
            console.print("âŒ è‡³å°‘éœ€è¦é…ç½®ä¸€ä¸ªLLMæä¾›å•†")
            return
        
        # Step 3: æœåŠ¡é…ç½®
        service_config = setup_service_config()
        if not service_config:
            console.print("âš ï¸  æœåŠ¡é…ç½®è·³è¿‡ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®ç»§ç»­")
            service_config = {"port": "9004", "enable_web": True}  # ä½¿ç”¨é»˜è®¤å€¼
        
        # Step 4: ä¿å­˜é…ç½®
        save_unified_config(comfyui_config, llm_configs, service_config)
        
        # Step 5: è¯¢é—®ç«‹å³å¯åŠ¨
        console.print("\nâœ… [bold green]é…ç½®å®Œæˆï¼[/bold green]")
        if questionary.confirm("ç«‹å³å¯åŠ¨ Pixelle MCPï¼Ÿ", default=True, instruction="(Y/n)").ask():
            start_pixelle_server()
            
    except KeyboardInterrupt:
        console.print("\n\nâŒ é…ç½®å·²å–æ¶ˆï¼ˆæŒ‰ä¸‹äº† Ctrl+Cï¼‰")
        console.print("ğŸ’¡ æ‚¨å¯ä»¥éšæ—¶é‡æ–°è¿è¡Œ [bold]pixelle[/bold] æ¥é…ç½®")
    except Exception as e:
        console.print(f"\nâŒ é…ç½®è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        console.print("ğŸ’¡ æ‚¨å¯ä»¥é‡æ–°è¿è¡Œ [bold]pixelle[/bold] æ¥é‡è¯•")


def setup_comfyui(default_url: str = None):
    """é…ç½®ComfyUI - ç¬¬ä¸€æ­¥"""
    console.print(Panel(
        "ğŸ§© [bold]ComfyUI é…ç½®[/bold]\n\n"
        "Pixelle MCP éœ€è¦è¿æ¥åˆ°æ‚¨çš„ ComfyUI æœåŠ¡æ¥æ‰§è¡Œå·¥ä½œæµã€‚\n"
        "ComfyUI æ˜¯ä¸€ä¸ªå¼ºå¤§çš„AIå·¥ä½œæµç¼–è¾‘å™¨ï¼Œå¦‚æœæ‚¨è¿˜æ²¡æœ‰å®‰è£…ï¼Œ\n"
        "è¯·è®¿é—®ï¼šhttps://github.com/comfyanonymous/ComfyUI",
        title="Step 1/4: ComfyUI é…ç½®",
        border_style="blue"
    ))
    
    # æ‰‹åŠ¨é…ç½®
    console.print("\nğŸ“ è¯·é…ç½® ComfyUI æœåŠ¡åœ°å€")
    console.print("ğŸ’¡ å¦‚æœé€‰æ‹©'n'ï¼Œå°†å…è®¸æ‚¨è¾“å…¥è‡ªå®šä¹‰åœ°å€")
    
    # ä½¿ç”¨ä¼ å…¥çš„é»˜è®¤å€¼æˆ–ä»£ç é»˜è®¤å€¼
    final_default_url = default_url or "http://localhost:8188"
    use_default = questionary.confirm(
        f"ä½¿ç”¨é»˜è®¤åœ°å€ {final_default_url}ï¼Ÿ",
        default=True,
        instruction="(Y/n)"
    ).ask()
    
    if use_default:
        url = final_default_url
        console.print(f"âœ… ä½¿ç”¨é»˜è®¤åœ°å€: {url}")
    else:
        url = questionary.text(
            "è¯·è¾“å…¥è‡ªå®šä¹‰ ComfyUI åœ°å€:",
            instruction="(ä¾‹å¦‚: http://192.168.1.100:8188)"
        ).ask()
    
    if not url:
        return None
    
    # æµ‹è¯•è¿æ¥
    console.print(f"ğŸ”Œ æ­£åœ¨æµ‹è¯•è¿æ¥ {url}...")
    if test_comfyui_connection(url):
        console.print("âœ… [bold green]ComfyUI è¿æ¥æˆåŠŸï¼[/bold green]")
        return {"url": url}
    else:
        console.print("âŒ [bold red]æ— æ³•è¿æ¥åˆ° ComfyUI[/bold red]")
        console.print("è¯·æ£€æŸ¥ï¼š")
        console.print("1. ComfyUI æ˜¯å¦æ­£åœ¨è¿è¡Œ")
        console.print("2. åœ°å€æ˜¯å¦æ­£ç¡®")
        console.print("3. ç½‘ç»œæ˜¯å¦ç•…é€š")
        
        # è¯¢é—®æ˜¯å¦è·³è¿‡æµ‹è¯•
        skip_test = questionary.confirm(
            "æ˜¯å¦è·³è¿‡è¿æ¥æµ‹è¯•ï¼Ÿ",
            default=True,
            instruction="(Y/nï¼Œè·³è¿‡å°†ç›´æ¥ä½¿ç”¨æ‚¨å¡«å†™çš„åœ°å€)"
        ).ask()
        
        if skip_test:
            console.print(f"â­ï¸  å·²è·³è¿‡è¿æ¥æµ‹è¯•ï¼Œå°†ä½¿ç”¨åœ°å€: {url}")
            return {"url": url}
        else:
            # é‡æ–°æµ‹è¯•ï¼Œä½†ä¿æŒç”¨æˆ·å¡«å†™çš„åœ°å€
            return setup_comfyui(url)



def test_comfyui_connection(url: str) -> bool:
    """æµ‹è¯•ComfyUIè¿æ¥"""
    try:
        response = requests.get(urljoin(url, "/system_stats"), timeout=3)
        return response.status_code == 200
    except:
        return False


def setup_multiple_llm_providers():
    """é…ç½®å¤šä¸ªLLMæä¾›å•† - ç¬¬äºŒæ­¥"""
    console.print(Panel(
        "ğŸ¤– [bold]LLM æä¾›å•†é…ç½®[/bold]\n\n"
        "Pixelle MCP æ”¯æŒå¤šç§LLMæä¾›å•†ï¼Œæ‚¨å¯ä»¥é…ç½®ä¸€ä¸ªæˆ–å¤šä¸ªã€‚\n"
        "é…ç½®å¤šä¸ªæä¾›å•†çš„å¥½å¤„ï¼š\n"
        "â€¢ å¯ä»¥åœ¨ä¸åŒåœºæ™¯ä¸‹ä½¿ç”¨ä¸åŒæ¨¡å‹\n"
        "â€¢ æä¾›å¤‡é€‰æ–¹æ¡ˆï¼Œæé«˜æœåŠ¡å¯ç”¨æ€§\n"
        "â€¢ æŸäº›æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¡¨ç°æ›´å¥½",
        title="Step 2/4: LLM æä¾›å•†é…ç½®",
        border_style="green"
    ))
    
    configured_providers = []
    
    while True:
        # æ˜¾ç¤ºå¯é€‰çš„æä¾›å•†
        available_providers = [
            questionary.Choice("ğŸ”¥ OpenAI (æ¨è) - GPT-4ã€GPT-3.5ç­‰", "openai"),
            questionary.Choice("ğŸ  Ollama (æœ¬åœ°) - å…è´¹æœ¬åœ°æ¨¡å‹", "ollama"),
            questionary.Choice("ğŸ’ Google Gemini - Googleæœ€æ–°æ¨¡å‹", "gemini"),
            questionary.Choice("ğŸš€ DeepSeek - æ€§ä»·æ¯”æé«˜çš„ä»£ç æ¨¡å‹", "deepseek"),
            questionary.Choice("ğŸ¤– Claude - Anthropicçš„å¼ºå¤§æ¨¡å‹", "claude"),
            questionary.Choice("ğŸŒŸ Qwen - é˜¿é‡Œå·´å·´é€šä¹‰åƒé—®", "qwen"),
        ]
        
        # è¿‡æ»¤å·²é…ç½®çš„æä¾›å•†
        remaining_providers = [p for p in available_providers 
                             if p.value not in [cp["provider"] for cp in configured_providers]]
        
        if not remaining_providers:
            console.print("âœ… å·²é…ç½®æ‰€æœ‰å¯ç”¨çš„LLMæä¾›å•†ï¼Œè‡ªåŠ¨è¿›å…¥ä¸‹ä¸€æ­¥")
            break
        
        # æ˜¾ç¤ºå½“å‰å·²é…ç½®çš„æä¾›å•†
        if configured_providers:
            console.print("\nğŸ“‹ [bold]å·²é…ç½®çš„æä¾›å•†ï¼š[/bold]")
            for provider in configured_providers:
                console.print(f"  âœ… {provider['provider'].title()}")
        
        # é€‰æ‹©è¦é…ç½®çš„æä¾›å•†
        if configured_providers:
            remaining_providers.append(questionary.Choice("ğŸ å®Œæˆé…ç½®", "done"))
        
        # æ€»æ˜¯æ·»åŠ é€€å‡ºé€‰é¡¹
        remaining_providers.append(questionary.Choice("âŒ å–æ¶ˆé…ç½®", "cancel"))
        
        provider = questionary.select(
            "é€‰æ‹©è¦é…ç½®çš„LLMæä¾›å•†ï¼š" if not configured_providers else "é€‰æ‹©è¦ç»§ç»­é…ç½®çš„LLMæä¾›å•†ï¼š",
            choices=remaining_providers
        ).ask()
        
        if provider == "cancel":
            if questionary.confirm("ç¡®å®šè¦å–æ¶ˆé…ç½®å—ï¼Ÿ", default=False, instruction="(y/N)").ask():
                console.print("âŒ é…ç½®å·²å–æ¶ˆ")
                return None
            else:
                continue  # ç»§ç»­é…ç½®å¾ªç¯
        
        if provider == "done":
            break
        
        # é…ç½®å…·ä½“çš„æä¾›å•†
        provider_config = configure_specific_llm(provider)
        if provider_config:
            configured_providers.append(provider_config)
            
            # æ˜¾ç¤ºé€‰æ‹©çš„æ¨¡å‹
            models = provider_config.get('models', '')
            if models:
                model_list = [m.strip() for m in models.split(',')]
                model_display = 'ã€'.join(model_list)
                console.print(f"âœ… [bold green]{provider.title()} é…ç½®æˆåŠŸï¼[/bold green]")
                console.print(f"ğŸ“‹ æ‚¨é€‰æ‹©äº† {model_display} æ¨¡å‹\n")
            else:
                console.print(f"âœ… [bold green]{provider.title()} é…ç½®æˆåŠŸï¼[/bold green]\n")
        
        if not configured_providers:
            console.print("âš ï¸  è‡³å°‘éœ€è¦é…ç½®ä¸€ä¸ªLLMæä¾›å•†æ‰èƒ½ç»§ç»­")
        else:
            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æœªé…ç½®çš„æä¾›å•†
            # remaining_providerså·²ç»è¿‡æ»¤æ‰å·²é…ç½®çš„ï¼Œä¸”ä¼šæ·»åŠ "å®Œæˆé…ç½®"å’Œ"å–æ¶ˆé…ç½®"é€‰é¡¹
            actual_remaining = len([p for p in remaining_providers if p.value not in ["done", "cancel"]])
            if actual_remaining > 0:
                if not questionary.confirm("æ˜¯å¦ç»§ç»­é…ç½®å…¶ä»–LLMæä¾›å•†ï¼Ÿ", default=False, instruction="(y/N)").ask():
                    break
            else:
                # æ‰€æœ‰æä¾›å•†éƒ½å·²é…ç½®å®Œæ¯•ï¼Œè‡ªåŠ¨è¿›å…¥ä¸‹ä¸€æ­¥
                break
    
    return configured_providers


def configure_specific_llm(provider: str) -> Optional[Dict]:
    """é…ç½®å…·ä½“çš„LLMæä¾›å•†"""
    
    if provider == "openai":
        return configure_openai()
    elif provider == "ollama":
        return configure_ollama()
    elif provider == "gemini":
        return configure_gemini()
    elif provider == "deepseek":
        return configure_deepseek()
    elif provider == "claude":
        return configure_claude()
    elif provider == "qwen":
        return configure_qwen()
    
    return None


def configure_openai() -> Optional[Dict]:
    """é…ç½®OpenAI"""
    console.print("\nğŸ”¥ [bold]é…ç½® OpenAI å…¼å®¹æ¥å£[/bold]")
    console.print("æ”¯æŒ OpenAI å®˜æ–¹ä»¥åŠæ‰€æœ‰å…¼å®¹ OpenAI SDK åè®®çš„æä¾›å•†")
    console.print("åŒ…æ‹¬ä½†ä¸é™äºï¼šOpenAIã€Azure OpenAIã€å„ç§ç¬¬ä¸‰æ–¹ä»£ç†æœåŠ¡ç­‰")
    console.print("è·å– OpenAI å®˜æ–¹ API Key: https://platform.openai.com/api-keys\n")
    
    api_key = questionary.password("è¯·è¾“å…¥æ‚¨çš„ OpenAI API Key:").ask()
    if not api_key:
        return None
    
    console.print("ğŸ’¡ å¦‚æœä½¿ç”¨ä»£ç†æˆ–ç¬¬ä¸‰æ–¹æœåŠ¡ï¼Œé€‰æ‹©'n'è¾“å…¥è‡ªå®šä¹‰åœ°å€")
    default_base_url = "https://api.openai.com/v1"
    use_default_url = questionary.confirm(
        f"ä½¿ç”¨é»˜è®¤ API åœ°å€ {default_base_url}ï¼Ÿ",
        default=True,
        instruction="(Y/n)"
    ).ask()
    
    if use_default_url:
        base_url = default_base_url
        console.print(f"âœ… ä½¿ç”¨é»˜è®¤åœ°å€: {base_url}")
    else:
        base_url = questionary.text(
            "è¯·è¾“å…¥è‡ªå®šä¹‰ API åœ°å€:",
            instruction="(ä¾‹å¦‚: https://your-proxy.com/v1)"
        ).ask()
    
    # å°è¯•è·å–æ¨¡å‹åˆ—è¡¨
    console.print("ğŸ” æ­£åœ¨è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨...")
    available_models = get_openai_models(api_key, base_url)
    
    if available_models:
        console.print(f"ğŸ“‹ å‘ç° {len(available_models)} ä¸ªå¯ç”¨æ¨¡å‹")
        
        # é¢„é€‰æ¨èæ¨¡å‹
        recommended_models = []
        for model in ["gpt-4o-mini", "gpt-4o", "gpt-4", "gpt-3.5-turbo"]:
            if model in available_models:
                recommended_models.append(model)
        
        if recommended_models:
            console.print(f"ğŸ’¡ å·²ä¸ºæ‚¨é¢„é€‰æ¨èæ¨¡å‹: {', '.join(recommended_models)}")
        
        # ç›´æ¥æä¾›å¤šé€‰ç•Œé¢
        # åˆ›å»ºchoicesåˆ—è¡¨ï¼Œå¹¶æ ‡è®°æ¨èæ¨¡å‹ä¸ºé»˜è®¤é€‰ä¸­
        choices = []
        for model in available_models:
            if model in recommended_models:
                choices.append(questionary.Choice(f"{model} (æ¨è)", model, checked=True))
            else:
                choices.append(questionary.Choice(model, model, checked=False))
        
        selected_models = questionary.checkbox(
            "è¯·é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹ï¼ˆç©ºæ ¼é€‰æ‹©/å–æ¶ˆï¼Œå›è½¦ç¡®è®¤ï¼‰:",
            choices=choices,
            instruction="ä½¿ç”¨æ–¹å‘é”®å¯¼èˆªï¼Œç©ºæ ¼é”®é€‰æ‹©/å–æ¶ˆé€‰æ‹©ï¼Œå›è½¦é”®ç¡®è®¤"
        ).ask()
        
        if selected_models:
            models = ",".join(selected_models)
            console.print(f"âœ… å·²é€‰æ‹©æ¨¡å‹: {models}")
        else:
            console.print("âš ï¸  æœªé€‰æ‹©ä»»ä½•æ¨¡å‹ï¼Œå°†ä½¿ç”¨æ‰‹åŠ¨è¾“å…¥")
            models = questionary.text(
                "è¯·è¾“å…¥è‡ªå®šä¹‰æ¨¡å‹:",
                instruction="(å¤šä¸ªæ¨¡å‹ç”¨è‹±æ–‡é€—å·åˆ†éš”)"
            ).ask()
    else:
        console.print("âš ï¸  æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        default_models = "gpt-4o-mini,gpt-4o"
        use_default_models = questionary.confirm(
            f"ä½¿ç”¨é»˜è®¤æ¨èæ¨¡å‹ {default_models}ï¼Ÿ",
            default=True,
            instruction="(Y/n)"
        ).ask()
        
        if use_default_models:
            models = default_models
            console.print(f"âœ… ä½¿ç”¨é»˜è®¤æ¨¡å‹: {models}")
        else:
            models = questionary.text(
                "è¯·è¾“å…¥è‡ªå®šä¹‰æ¨¡å‹:",
                instruction="(å¤šä¸ªæ¨¡å‹ç”¨è‹±æ–‡é€—å·åˆ†éš”ï¼Œä¾‹å¦‚: gpt-4,gpt-3.5-turbo)"
            ).ask()
    
    return {
        "provider": "openai",
        "api_key": api_key,
        "base_url": base_url,
        "models": models
    }


def configure_ollama() -> Optional[Dict]:
    """é…ç½®Ollama"""
    console.print("\nğŸ  [bold]é…ç½® Ollama (æœ¬åœ°æ¨¡å‹)[/bold]")
    console.print("Ollama å¯ä»¥åœ¨æœ¬åœ°è¿è¡Œå¼€æºæ¨¡å‹ï¼Œå®Œå…¨å…è´¹ä¸”æ•°æ®ä¸å‡ºæœ¬æœº")
    console.print("å®‰è£… Ollama: https://ollama.ai\n")
    
    console.print("ğŸ’¡ å¦‚æœOllamaè¿è¡Œåœ¨å…¶ä»–åœ°å€ï¼Œé€‰æ‹©'n'è¾“å…¥è‡ªå®šä¹‰åœ°å€")
    default_base_url = "http://localhost:11434/v1"
    use_default_url = questionary.confirm(
        f"ä½¿ç”¨é»˜è®¤ Ollama åœ°å€ {default_base_url}ï¼Ÿ",
        default=True,
        instruction="(Y/n)"
    ).ask()
    
    if use_default_url:
        base_url = default_base_url
        console.print(f"âœ… ä½¿ç”¨é»˜è®¤åœ°å€: {base_url}")
    else:
        base_url = questionary.text(
            "è¯·è¾“å…¥è‡ªå®šä¹‰ Ollama åœ°å€:",
            instruction="(ä¾‹å¦‚: http://192.168.1.100:11434/v1)"
        ).ask()
    
    # æµ‹è¯•è¿æ¥
    console.print("ğŸ”Œ æ­£åœ¨æµ‹è¯• Ollama è¿æ¥...")
    if test_ollama_connection(base_url):
        console.print("âœ… Ollama è¿æ¥æˆåŠŸ")
        
        # è·å–å¯ç”¨æ¨¡å‹
        models = get_ollama_models(base_url)
        if models:
            console.print(f"ğŸ“‹ å‘ç° {len(models)} ä¸ªå¯ç”¨æ¨¡å‹")
            selected_models = questionary.checkbox(
                "é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹:",
                choices=[questionary.Choice(model, model) for model in models]
            ).ask()
            
            if selected_models:
                return {
                    "provider": "ollama", 
                    "base_url": base_url,
                    "models": ",".join(selected_models)
                }
        else:
            console.print("âš ï¸  æœªå‘ç°å¯ç”¨æ¨¡å‹ï¼Œæ‚¨å¯èƒ½éœ€è¦å…ˆä¸‹è½½æ¨¡å‹")
            console.print("ä¾‹å¦‚ï¼šollama pull llama2")
            
            models = questionary.text(
                "æ‰‹åŠ¨æŒ‡å®šæ¨¡å‹:",
                instruction="(å¤šä¸ªæ¨¡å‹ç”¨è‹±æ–‡é€—å·åˆ†éš”)"
            ).ask()
            
            if models:
                return {
                    "provider": "ollama",
                    "base_url": base_url, 
                    "models": models
                }
    else:
        console.print("âŒ æ— æ³•è¿æ¥åˆ° Ollama")
        console.print("è¯·ç¡®ä¿ Ollama æ­£åœ¨è¿è¡Œ")
        
    return None


def configure_gemini() -> Optional[Dict]:
    """é…ç½®Gemini"""
    console.print("\nğŸ’ [bold]é…ç½® Google Gemini[/bold]")
    console.print("Google Gemini æ˜¯Googleæœ€æ–°çš„å¤§è¯­è¨€æ¨¡å‹")
    console.print("è·å–API Key: https://makersuite.google.com/app/apikey\n")
    
    api_key = questionary.password("è¯·è¾“å…¥æ‚¨çš„ Gemini API Key:").ask()
    if not api_key:
        return None
    
    models = questionary.text(
        "å¯ç”¨æ¨¡å‹ (å¯é€‰):",
        default="gemini-pro,gemini-pro-vision",
        instruction="(å¤šä¸ªæ¨¡å‹ç”¨è‹±æ–‡é€—å·åˆ†éš”)"
    ).ask()
    
    return {
        "provider": "gemini",
        "api_key": api_key,
        "models": models
    }


def configure_deepseek() -> Optional[Dict]:
    """é…ç½®DeepSeek"""
    console.print("\nğŸš€ [bold]é…ç½® DeepSeek[/bold]")
    console.print("DeepSeek æ˜¯æ€§ä»·æ¯”æé«˜çš„ä»£ç ä¸“ç”¨æ¨¡å‹")
    console.print("è·å–API Key: https://platform.deepseek.com/api_keys\n")
    
    api_key = questionary.password("è¯·è¾“å…¥æ‚¨çš„ DeepSeek API Key:").ask()
    if not api_key:
        return None
    
    models = questionary.text(
        "å¯ç”¨æ¨¡å‹ (å¯é€‰):",
        default="deepseek-chat,deepseek-coder",
        instruction="(å¤šä¸ªæ¨¡å‹ç”¨è‹±æ–‡é€—å·åˆ†éš”)"
    ).ask()
    
    return {
        "provider": "deepseek",
        "api_key": api_key,
        "models": models
    }


def configure_claude() -> Optional[Dict]:
    """é…ç½®Claude"""
    console.print("\nğŸ¤– [bold]é…ç½® Claude[/bold]")
    console.print("Claude æ˜¯ Anthropic å¼€å‘çš„å¼ºå¤§AIåŠ©æ‰‹")
    console.print("è·å–API Key: https://console.anthropic.com/\n")
    
    api_key = questionary.password("è¯·è¾“å…¥æ‚¨çš„ Claude API Key:").ask()
    if not api_key:
        return None
    
    models = questionary.text(
        "å¯ç”¨æ¨¡å‹ (å¯é€‰):",
        default="claude-3-sonnet-20240229,claude-3-haiku-20240307",
        instruction="(å¤šä¸ªæ¨¡å‹ç”¨è‹±æ–‡é€—å·åˆ†éš”)"
    ).ask()
    
    return {
        "provider": "claude",
        "api_key": api_key,
        "models": models
    }


def configure_qwen() -> Optional[Dict]:
    """é…ç½®Qwen"""
    console.print("\nğŸŒŸ [bold]é…ç½® é˜¿é‡Œå·´å·´é€šä¹‰åƒé—®[/bold]")
    console.print("é€šä¹‰åƒé—®æ˜¯é˜¿é‡Œå·´å·´å¼€å‘çš„å¤§è¯­è¨€æ¨¡å‹")
    console.print("è·å–API Key: https://dashscope.console.aliyun.com/\n")
    
    api_key = questionary.password("è¯·è¾“å…¥æ‚¨çš„ Qwen API Key:").ask()
    if not api_key:
        return None
    
    models = questionary.text(
        "å¯ç”¨æ¨¡å‹ (å¯é€‰):",
        default="qwen-plus,qwen-turbo",
        instruction="(å¤šä¸ªæ¨¡å‹ç”¨è‹±æ–‡é€—å·åˆ†éš”)"
    ).ask()
    
    return {
        "provider": "qwen",
        "api_key": api_key, 
        "models": models
    }


def test_ollama_connection(base_url: str) -> bool:
    """æµ‹è¯•Ollamaè¿æ¥"""
    try:
        # ç§»é™¤/v1åç¼€æ¥æµ‹è¯•åŸºç¡€è¿æ¥
        test_url = base_url.replace("/v1", "")
        response = requests.get(f"{test_url}/api/tags", timeout=5)
        return response.status_code == 200
    except:
        return False


def get_openai_models(api_key: str, base_url: str) -> List[str]:
    """è·å–OpenAIå¯ç”¨æ¨¡å‹"""
    try:
        headers = {"Authorization": f"Bearer {api_key}"}
        response = requests.get(f"{base_url}/models", headers=headers, timeout=10)
        if response.status_code == 200:
            data = response.json()
            models = [model["id"] for model in data.get("data", [])]
            # è¿‡æ»¤å‡ºGPTæ¨¡å‹ï¼Œæ’é™¤embeddingsç­‰å…¶ä»–ç±»å‹
            gpt_models = [m for m in models if any(keyword in m.lower() for keyword in ["gpt", "chat", "davinci", "text"])]
            return sorted(gpt_models)
    except Exception as e:
        console.print(f"âš ï¸  è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
    return []


def get_ollama_models(base_url: str) -> List[str]:
    """è·å–Ollamaå¯ç”¨æ¨¡å‹"""
    try:
        test_url = base_url.replace("/v1", "")
        response = requests.get(f"{test_url}/api/tags", timeout=5)
        if response.status_code == 200:
            data = response.json()
            return [model["name"] for model in data.get("models", [])]
    except:
        pass
    return []


def setup_service_config():
    """é…ç½®æœåŠ¡é€‰é¡¹ - ç¬¬ä¸‰æ­¥"""
    console.print(Panel(
        "âš™ï¸ [bold]æœåŠ¡é…ç½®[/bold]\n\n"
        "é…ç½® Pixelle MCP çš„æœåŠ¡é€‰é¡¹ï¼ŒåŒ…æ‹¬ç«¯å£ã€ä¸»æœºåœ°å€ç­‰ã€‚",
        title="Step 3/4: æœåŠ¡é…ç½®",
        border_style="yellow"
    ))
    
    default_port = "9004"
    port = questionary.text(
        "æœåŠ¡ç«¯å£:",
        default=default_port,
        instruction="(ç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤ç«¯å£9004ï¼Œæˆ–è¾“å…¥å…¶ä»–ç«¯å£å·)"
    ).ask()
    
    if not port:
        port = default_port
    
    console.print(f"âœ… æœåŠ¡å°†åœ¨ç«¯å£ {port} å¯åŠ¨")
    
    # é…ç½®ä¸»æœºåœ°å€
    console.print("\nğŸ“¡ [bold yellow]ä¸»æœºåœ°å€é…ç½®[/bold yellow]")
    console.print("ğŸ” [dim]ä¸»æœºåœ°å€å†³å®šäº†æœåŠ¡ç›‘å¬çš„ç½‘ç»œæ¥å£ï¼š[/dim]")
    console.print("   â€¢ [green]localhost[/green] - ä»…æœ¬æœºè®¿é—®ï¼ˆæ¨èç”¨äºæœ¬åœ°å¼€å‘ï¼‰")
    console.print("   â€¢ [yellow]0.0.0.0[/yellow] - å…è®¸å¤–éƒ¨è®¿é—®ï¼ˆç”¨äºæœåŠ¡å™¨éƒ¨ç½²æˆ–å±€åŸŸç½‘å…±äº«ï¼‰")
    console.print("\nâš ï¸  [bold red]å®‰å…¨æç¤ºï¼š[/bold red]")
    console.print("   é€‰æ‹© 0.0.0.0 æ—¶ï¼Œè¯·ç¡®ä¿ï¼š")
    console.print("   1. å·²é…ç½®é˜²ç«å¢™è§„åˆ™")
    console.print("   2. å·²è®¾ç½®å¼ºå¯†ç è®¤è¯")
    console.print("   3. åœ¨å¯ä¿¡ç½‘ç»œç¯å¢ƒä¸­è¿è¡Œ")
    
    default_host = "localhost"
    host = questionary.text(
        "ä¸»æœºåœ°å€:",
        default=default_host,
        instruction="(localhost=æœ¬æœºè®¿é—®, 0.0.0.0=å…è®¸å¤–éƒ¨è®¿é—®)"
    ).ask()
    
    if not host:
        host = default_host
    
    if host == "0.0.0.0":
        console.print("âš ï¸  [bold yellow]å·²è®¾ç½®ä¸ºå…è®¸å¤–éƒ¨è®¿é—®ï¼Œè¯·ç¡®ä¿ç½‘ç»œå®‰å…¨ï¼[/bold yellow]")
    else:
        console.print(f"âœ… æœåŠ¡å°†åœ¨ {host} ä¸Šç›‘å¬")
    
    return {
        "port": port,
        "host": host,
    }


def save_unified_config(comfyui_config: Dict, llm_configs: List[Dict], service_config: Dict):
    """ä¿å­˜ç»Ÿä¸€é…ç½®åˆ°.envæ–‡ä»¶"""
    console.print(Panel(
        "ğŸ’¾ [bold]ä¿å­˜é…ç½®[/bold]\n\n"
        "æ­£åœ¨å°†é…ç½®ä¿å­˜åˆ° .env æ–‡ä»¶...",
        title="Step 4/4: ä¿å­˜é…ç½®",
        border_style="magenta"
    ))
    
    env_lines = [
        "# Pixelle MCP Project Environment Variables Configuration",
        "# æ­¤æ–‡ä»¶ç”± Pixelle MCP CLI è‡ªåŠ¨ç”Ÿæˆï¼Œæ‚¨å¯ä»¥æ‰‹åŠ¨ç¼–è¾‘æ¥ä¿®æ”¹é…ç½®",
        "# Copy this file to .env and modify the configuration values according to your actual situation",
        "",
        "# ======== Basic Service Configuration ========",
        "# Service configuration",
        f"HOST={service_config['host']}",
        f"PORT={service_config['port']}",
        "# Optional, used to specify public access URL, generally not needed for local services,",
        "# configure when service is not on local machine",
        "PUBLIC_READ_URL=\"\"",
        "",
        "# ======== ComfyUI Integration Configuration ========",
        "# ComfyUI service address",
        f"COMFYUI_BASE_URL={comfyui_config['url']}",
        "# ComfyUI API Key (required if API Nodes are used in workflows,",
        "# get it from: https://platform.comfy.org/profile/api-keys)",
        "COMFYUI_API_KEY=\"\"",
        "# Cookies used when calling ComfyUI interface, configure if ComfyUI service requires authentication",
        "COMFYUI_COOKIES=\"\"",
        "# Executor type for calling ComfyUI interface, supports websocket and http (both are generally supported)",
        "COMFYUI_EXECUTOR_TYPE=http",
        "",
        "# ======== Chainlit Framework Configuration ========",
        "# Chainlit auth secret (used for chainlit auth, can be reused or randomly generated)",
        "CHAINLIT_AUTH_SECRET=\"changeme-generate-a-secure-secret-key\"",
        f"CHAINLIT_AUTH_ENABLED=true",
        "CHAINLIT_SAVE_STARTER_ENABLED=false",
        ""
    ]
    
    # æ·»åŠ LLMé…ç½®
    env_lines.append("# ======== LLM Model Configuration ========")
    
    for llm_config in llm_configs:
        provider = llm_config["provider"].upper()
        
        if provider == "OPENAI":
            env_lines.extend([
                "# OpenAI configuration",
                f"OPENAI_BASE_URL=\"{llm_config.get('base_url', 'https://api.openai.com/v1')}\"",
                "# Get your API key at: https://platform.openai.com/api-keys",
                f"OPENAI_API_KEY=\"{llm_config['api_key']}\"",
                "# List OpenAI models to be used, if multiple, separate with English commas",
                f"CHAINLIT_CHAT_OPENAI_MODELS=\"{llm_config.get('models', 'gpt-4o-mini')}\"",
            ])
        elif provider == "OLLAMA":
            env_lines.extend([
                "# Ollama configuration (local models)",
                f"OLLAMA_BASE_URL=\"{llm_config.get('base_url', 'http://localhost:11434/v1')}\"",
                "# List Ollama models to be used, if multiple, separate with English commas",
                f"OLLAMA_MODELS=\"{llm_config.get('models', '')}\"",
            ])
        elif provider == "GEMINI":
            env_lines.extend([
                "# Gemini configuration",
                f"GEMINI_BASE_URL=\"https://generativelanguage.googleapis.com/v1beta\"",
                "# Get your API key at: https://aistudio.google.com/app/apikey",
                f"GEMINI_API_KEY=\"{llm_config['api_key']}\"",
                "# List Gemini models to be used, if multiple, separate with English commas",
                f"GEMINI_MODELS=\"{llm_config.get('models', '')}\"",
            ])
        elif provider == "DEEPSEEK":
            env_lines.extend([
                "# DeepSeek configuration",
                f"DEEPSEEK_BASE_URL=\"https://api.deepseek.com\"",
                "# Get your API key at: https://platform.deepseek.com/api_keys",
                f"DEEPSEEK_API_KEY=\"{llm_config['api_key']}\"",
                "# List DeepSeek models to be used, if multiple, separate with English commas",
                f"DEEPSEEK_MODELS=\"{llm_config.get('models', '')}\"",
            ])
        elif provider == "CLAUDE":
            env_lines.extend([
                "# Claude (Anthropic) configuration",
                f"CLAUDE_BASE_URL=\"https://api.anthropic.com\"",
                "# Get your API key at: https://console.anthropic.com/settings/keys",
                f"CLAUDE_API_KEY=\"{llm_config['api_key']}\"",
                "# List Claude models to be used, if multiple, separate with English commas",
                f"CLAUDE_MODELS=\"{llm_config.get('models', '')}\"",
            ])
        elif provider == "QWEN":
            env_lines.extend([
                "# Qwen (Alibaba Cloud) configuration",
                f"QWEN_BASE_URL=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"",
                "# Get your API key at: https://bailian.console.aliyun.com/?tab=model#/api-key",
                f"QWEN_API_KEY=\"{llm_config['api_key']}\"",
                "# List Qwen models to be used, if multiple, separate with English commas",
                f"QWEN_MODELS=\"{llm_config.get('models', '')}\"",
            ])
        
        env_lines.append("")
    
    # è®¾ç½®é»˜è®¤æ¨¡å‹ï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ªé…ç½®çš„LLMçš„ç¬¬ä¸€ä¸ªæ¨¡å‹ï¼‰
    if llm_configs:
        first_llm = llm_configs[0]
        models = first_llm.get('models', '')
        if models:
            default_model = models.split(',')[0].strip()
            env_lines.extend([
                "# Optional, default model for conversations (can be from any provider above)",
                f"CHAINLIT_CHAT_DEFAULT_MODEL=\"{default_model}\"",
                ""
            ])
    

    
    # å†™å…¥.envæ–‡ä»¶
    with open('.env', 'w', encoding='utf-8') as f:
        f.write('\n'.join(env_lines))
    
    console.print("âœ… [bold green]é…ç½®å·²ä¿å­˜åˆ° .env æ–‡ä»¶[/bold green]")
    
    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šç«‹å³é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡å’Œsettings
    reload_config()


def reload_config():
    """é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡å’Œsettingsé…ç½®"""
    import os
    from dotenv import load_dotenv
    
    # å¼ºåˆ¶é‡æ–°åŠ è½½.envæ–‡ä»¶
    load_dotenv(override=True)
    
    # é‡æ–°è®¾ç½®Chainlitç¯å¢ƒå˜é‡
    from pixelle.utils.os_util import get_root_path
    os.environ["CHAINLIT_APP_ROOT"] = get_root_path()
    
    # æ›´æ–°å…¨å±€settingså®ä¾‹çš„å€¼
    from pixelle import settings as settings_module
    
    # åˆ›å»ºæ–°çš„Settingså®ä¾‹æ¥è·å–æœ€æ–°é…ç½®
    from pixelle.settings import Settings
    new_settings = Settings()
    
    # æ›´æ–°å…¨å±€settingså¯¹è±¡çš„å±æ€§
    for field_name in new_settings.model_fields:
        setattr(settings_module.settings, field_name, getattr(new_settings, field_name))
    
    console.print("ğŸ”„ [bold blue]é…ç½®å·²é‡æ–°åŠ è½½[/bold blue]")


def show_main_menu():
    """æ˜¾ç¤ºä¸»èœå•"""
    console.print("\nğŸ“‹ [bold]å½“å‰é…ç½®çŠ¶æ€[/bold]")
    show_current_config()
    
    action = questionary.select(
        "è¯·é€‰æ‹©è¦æ‰§è¡Œçš„æ“ä½œ:",
        choices=[
            questionary.Choice("ğŸš€ å¯åŠ¨ Pixelle MCP", "start"),
            questionary.Choice("ğŸ”„ é‡æ–°å¼•å¯¼é…ç½®", "reconfig"),
            questionary.Choice("âœï¸ æ‰‹åŠ¨ç¼–è¾‘é…ç½®", "manual"),
            questionary.Choice("ğŸ“‹ æŸ¥çœ‹çŠ¶æ€", "status"),
            questionary.Choice("â“ å¸®åŠ©", "help"),
            questionary.Choice("âŒ é€€å‡º", "exit")
        ]
    ).ask()
    
    if action == "start":
        start_pixelle_server()
    elif action == "reconfig":
        run_fresh_setup_wizard()
    elif action == "manual":
        guide_manual_edit()
    elif action == "status":
        check_service_status()
    elif action == "help":
        show_help()
    elif action == "exit":
        console.print("ğŸ‘‹ å†è§ï¼")
    else:
        console.print(f"åŠŸèƒ½ {action} æ­£åœ¨å¼€å‘ä¸­...")


def show_current_config():
    """æ˜¾ç¤ºå½“å‰é…ç½®"""
    from pixelle.settings import settings
    
    # åˆ›å»ºé…ç½®è¡¨æ ¼
    table = Table(title="å½“å‰é…ç½®", show_header=True, header_style="bold magenta")
    table.add_column("é…ç½®é¡¹", style="cyan", width=20)
    table.add_column("å½“å‰å€¼", style="green")
    
    # æœåŠ¡é…ç½®
    table.add_row("æœåŠ¡åœ°å€", f"http://{settings.host}:{settings.port}")
    table.add_row("ComfyUIåœ°å€", settings.comfyui_base_url)
    
    # LLMé…ç½®
    providers = settings.get_configured_llm_providers()
    if providers:
        table.add_row("LLMæä¾›å•†", ", ".join(providers))
        models = settings.get_all_available_models()
        if models:
            table.add_row("å¯ç”¨æ¨¡å‹", f"{len(models)} ä¸ªæ¨¡å‹")
            table.add_row("é»˜è®¤æ¨¡å‹", settings.chainlit_chat_default_model)
    else:
        table.add_row("LLMæä¾›å•†", "[red]æœªé…ç½®[/red]")
    
    # Webç•Œé¢
    web_status = "å¯ç”¨" if settings.chainlit_auth_enabled else "ç¦ç”¨"
    table.add_row("Webç•Œé¢", web_status)
    
    console.print(table)


def run_fresh_setup_wizard():
    """é‡æ–°å¼•å¯¼é…ç½®ï¼ˆä¸é¦–æ¬¡é…ç½®å®Œå…¨ç›¸åŒçš„æµç¨‹ï¼‰"""
    console.print(Panel(
        "ğŸ”„ [bold]é‡æ–°å¼•å¯¼é…ç½® Pixelle MCP[/bold]\n\n"
        "å°†ä»å¤´å¼€å§‹è¿›è¡Œå®Œæ•´é…ç½®ï¼Œè¿™ä¸é¦–æ¬¡é…ç½®æ˜¯å®Œå…¨ç›¸åŒçš„æµç¨‹ã€‚\n"
        "ç°æœ‰é…ç½®å°†è¢«å…¨æ–°é…ç½®æ›¿æ¢ã€‚",
        title="é‡æ–°å¼•å¯¼é…ç½®",
        border_style="yellow"
    ))
    
    if not questionary.confirm("ç¡®å®šè¦é‡æ–°è¿›è¡Œå®Œæ•´é…ç½®å—ï¼Ÿ", default=True, instruction="(Y/n)").ask():
        console.print("âŒ é‡æ–°é…ç½®å·²å–æ¶ˆ")
        return
    
    console.print("\nğŸš€ [bold]å¼€å§‹é‡æ–°é…ç½®å‘å¯¼[/bold]\n")
    
    try:
        # Step 1: ComfyUIé…ç½®
        comfyui_config = setup_comfyui()
        if not comfyui_config:
            console.print("âš ï¸  ComfyUIé…ç½®è·³è¿‡ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®ç»§ç»­")
            comfyui_config = {"url": "http://localhost:8188"}  # ä½¿ç”¨é»˜è®¤å€¼
        
        # Step 2: LLMé…ç½®ï¼ˆå¯é…ç½®å¤šä¸ªï¼‰
        llm_configs = setup_multiple_llm_providers()
        if not llm_configs:
            console.print("âŒ è‡³å°‘éœ€è¦é…ç½®ä¸€ä¸ªLLMæä¾›å•†")
            return
        
        # Step 3: æœåŠ¡é…ç½®
        service_config = setup_service_config()
        if not service_config:
            console.print("âš ï¸  æœåŠ¡é…ç½®è·³è¿‡ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®ç»§ç»­")
            service_config = {"port": "9004", "host": "localhost"}  # ä½¿ç”¨é»˜è®¤å€¼
        
        # Step 4: ä¿å­˜é…ç½®
        save_unified_config(comfyui_config, llm_configs, service_config)
        
        # Step 5: è¯¢é—®ç«‹å³å¯åŠ¨
        console.print("\nâœ… [bold green]é‡æ–°é…ç½®å®Œæˆï¼[/bold green]")
        if questionary.confirm("ç«‹å³å¯åŠ¨ Pixelle MCPï¼Ÿ", default=True, instruction="(Y/n)").ask():
            start_pixelle_server()
            
    except KeyboardInterrupt:
        console.print("\n\nâŒ é‡æ–°é…ç½®å·²å–æ¶ˆï¼ˆæŒ‰ä¸‹äº† Ctrl+Cï¼‰")
        console.print("ğŸ’¡ æ‚¨å¯ä»¥éšæ—¶é‡æ–°è¿è¡Œ [bold]pixelle[/bold] æ¥é…ç½®")
    except Exception as e:
        console.print(f"\nâŒ é…ç½®è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        console.print("ğŸ’¡ æ‚¨å¯ä»¥é‡æ–°è¿è¡Œ [bold]pixelle[/bold] æ¥é‡è¯•")


def guide_manual_edit():
    """å¼•å¯¼ç”¨æˆ·æ‰‹åŠ¨ç¼–è¾‘é…ç½®"""
    console.print(Panel(
        "âœï¸ [bold]æ‰‹åŠ¨ç¼–è¾‘é…ç½®[/bold]\n\n"
        "é…ç½®æ–‡ä»¶åŒ…å«è¯¦ç»†çš„æ³¨é‡Šè¯´æ˜ï¼Œæ‚¨å¯ä»¥ç›´æ¥ç¼–è¾‘æ¥è‡ªå®šä¹‰é…ç½®ã€‚\n"
        "é…ç½®æ–‡ä»¶ä½ç½®ï¼š.env\n\n"
        "ğŸ’¡ å¦‚éœ€å®Œå…¨é‡æ–°é…ç½®ï¼Œåˆ é™¤ .env æ–‡ä»¶åé‡æ–°è¿è¡Œ 'pixelle'\n"
        "ğŸ’¡ ç¼–è¾‘å®Œæˆåï¼Œé‡æ–°è¿è¡Œ 'pixelle' æ¥åº”ç”¨é…ç½®",
        title="æ‰‹åŠ¨é…ç½®æŒ‡å—",
        border_style="green"
    ))
    
    # æ˜¾ç¤ºå½“å‰é…ç½®æ–‡ä»¶è·¯å¾„
    env_path = Path(".env").absolute()
    console.print(f"ğŸ“ é…ç½®æ–‡ä»¶è·¯å¾„: {env_path}")
    
    if not env_path.exists():
        console.print("\nâš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼")
        console.print("ğŸ’¡ è¯·å…ˆè¿è¡Œäº¤äº’å¼•å¯¼: é€‰æ‹©èœå•ä¸­çš„ 'ğŸ”„ é‡æ–°å¼•å¯¼é…ç½®'")
        console.print("ğŸ’¡ æˆ–è€…é€€å‡ºå¹¶é‡æ–°è¿è¡Œ [bold]pixelle[/bold] è¿›è¡Œé¦–æ¬¡é…ç½®")
        return
    
    # æä¾›ä¸€äº›å¸¸ç”¨ç¼–è¾‘å™¨çš„å»ºè®®
    console.print("\nğŸ’¡ æ¨èç¼–è¾‘å™¨:")
    console.print("â€¢ VS Code: code .env")
    console.print("â€¢ Nano: nano .env") 
    console.print("â€¢ Vim: vim .env")
    console.print("â€¢ æˆ–ä»»ä½•æ–‡æœ¬ç¼–è¾‘å™¨")
    
    console.print("\nğŸ“ å¸¸è§é…ç½®ä¿®æ”¹:")
    console.print("â€¢ æ›´æ¢ç«¯å£: ä¿®æ”¹ PORT=9004")
    console.print("â€¢ æ·»åŠ æ–°LLM: é…ç½®å¯¹åº”çš„ API_KEY")
    console.print("â€¢ ç¦ç”¨LLM: åˆ é™¤æˆ–æ¸…ç©ºå¯¹åº”çš„ API_KEY")
    console.print("â€¢ æ›´æ¢ComfyUI: ä¿®æ”¹ COMFYUI_BASE_URL")
    
    # è¯¢é—®æ˜¯å¦è¦æ‰“å¼€æ–‡ä»¶
    if questionary.confirm("æ˜¯å¦è¦åœ¨é»˜è®¤ç¼–è¾‘å™¨ä¸­æ‰“å¼€é…ç½®æ–‡ä»¶ï¼Ÿ", default=True, instruction="(Y/n)").ask():
        try:
            import subprocess
            import platform
            
            if platform.system() == "Darwin":  # macOS
                subprocess.run(["open", str(env_path)])
            elif platform.system() == "Windows":
                subprocess.run(["notepad", str(env_path)])
            else:  # Linux
                subprocess.run(["xdg-open", str(env_path)])
                
            console.print("âœ… å·²åœ¨é»˜è®¤ç¼–è¾‘å™¨ä¸­æ‰“å¼€é…ç½®æ–‡ä»¶")
        except Exception as e:
            console.print(f"âŒ æ— æ³•è‡ªåŠ¨æ‰“å¼€: {e}")
            console.print("ğŸ’¡ è¯·æ‰‹åŠ¨ç¼–è¾‘æ–‡ä»¶")
    
    console.print("\nğŸ“‹ é…ç½®å®Œæˆåï¼Œé‡æ–°è¿è¡Œ [bold]pixelle[/bold] æ¥åº”ç”¨é…ç½®")
    console.print("ğŸ—‘ï¸  å¦‚éœ€å®Œå…¨é‡æ–°é…ç½®ï¼Œåˆ é™¤ .env æ–‡ä»¶åé‡æ–°è¿è¡Œ [bold]pixelle[/bold]")


def check_port_in_use(port: int) -> bool:
    """æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨"""
    try:
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
            sock.settimeout(1)
            result = sock.connect_ex(('localhost', port))
            return result == 0
    except:
        return False


def get_process_using_port(port: int) -> Optional[str]:
    """è·å–å ç”¨ç«¯å£çš„è¿›ç¨‹ä¿¡æ¯"""
    try:
        for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
            try:
                # ä½¿ç”¨kindå‚æ•°åªè·å–TCPè¿æ¥ï¼Œæé«˜æ•ˆç‡
                for conn in proc.net_connections(kind='tcp'):
                    if conn.laddr.port == port and conn.status in [psutil.CONN_LISTEN, psutil.CONN_ESTABLISHED]:
                        status_desc = "ç›‘å¬ä¸­" if conn.status == psutil.CONN_LISTEN else "å·²å»ºç«‹è¿æ¥"
                        return f"{proc.info['name']} (PID: {proc.info['pid']}) - {status_desc}"
            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                continue
    except Exception as e:
        console.print(f"âš ï¸  è·å–è¿›ç¨‹ä¿¡æ¯å¤±è´¥: {e}")
    return None


def kill_process_on_port(port: int) -> bool:
    """ç»ˆæ­¢å ç”¨ç«¯å£çš„è¿›ç¨‹"""
    try:
        target_proc = None
        target_pid = None
        
        # é¦–å…ˆæ‰¾åˆ°å ç”¨ç«¯å£çš„è¿›ç¨‹
        for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
            try:
                for conn in proc.net_connections(kind='tcp'):
                    if conn.laddr.port == port and conn.status in [psutil.CONN_LISTEN, psutil.CONN_ESTABLISHED]:
                        target_proc = proc
                        target_pid = proc.pid
                        status_desc = "ç›‘å¬ä¸­" if conn.status == psutil.CONN_LISTEN else "å·²å»ºç«‹è¿æ¥"
                        console.print(f"ğŸ¯ æ‰¾åˆ°ç›®æ ‡è¿›ç¨‹: {proc.info['name']} (PID: {target_pid}) - {status_desc}")
                        break
                if target_proc:
                    break
            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                continue
        
        if not target_proc:
            console.print("âŒ æœªæ‰¾åˆ°å ç”¨ç«¯å£çš„è¿›ç¨‹")
            return False
        
        # å°è¯•ç»ˆæ­¢è¿›ç¨‹
        try:
            console.print(f"ğŸ”„ æ­£åœ¨ç»ˆæ­¢è¿›ç¨‹ {target_pid}...")
            target_proc.terminate()
            
            # ç­‰å¾…è¿›ç¨‹ç»ˆæ­¢
            try:
                target_proc.wait(timeout=3)
                console.print(f"âœ… è¿›ç¨‹ {target_pid} å·²æ­£å¸¸ç»ˆæ­¢")
                return True
            except psutil.TimeoutExpired:
                # å¦‚æœæ¸©å’Œç»ˆæ­¢å¤±è´¥ï¼Œå°è¯•å¼ºåˆ¶æ€æ­»
                console.print(f"âš ï¸  è¿›ç¨‹ {target_pid} æœªå“åº”terminateï¼Œå°è¯•å¼ºåˆ¶ç»ˆæ­¢...")
                target_proc.kill()
                try:
                    target_proc.wait(timeout=2)
                    console.print(f"âœ… è¿›ç¨‹ {target_pid} å·²å¼ºåˆ¶ç»ˆæ­¢")
                    return True
                except psutil.TimeoutExpired:
                    console.print(f"âŒ æ— æ³•ç»ˆæ­¢è¿›ç¨‹ {target_pid}")
                    return False
                    
        except psutil.NoSuchProcess:
            console.print(f"âœ… è¿›ç¨‹ {target_pid} å·²ä¸å­˜åœ¨")
            return True
        except psutil.AccessDenied:
            console.print(f"âŒ æƒé™ä¸è¶³ï¼Œæ— æ³•ç»ˆæ­¢è¿›ç¨‹ {target_pid}")
            # å°è¯•ä½¿ç”¨ç³»ç»Ÿå‘½ä»¤ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
            try:
                console.print("ğŸ”„ å°è¯•ä½¿ç”¨ç³»ç»Ÿå‘½ä»¤ç»ˆæ­¢è¿›ç¨‹...")
                import os
                os.system(f"kill -TERM {target_pid}")
                import time
                time.sleep(2)
                
                # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜å­˜åœ¨
                if not psutil.pid_exists(target_pid):
                    console.print(f"âœ… è¿›ç¨‹ {target_pid} å·²é€šè¿‡ç³»ç»Ÿå‘½ä»¤ç»ˆæ­¢")
                    return True
                else:
                    # å°è¯•å¼ºåˆ¶ç»ˆæ­¢
                    os.system(f"kill -KILL {target_pid}")
                    time.sleep(1)
                    if not psutil.pid_exists(target_pid):
                        console.print(f"âœ… è¿›ç¨‹ {target_pid} å·²å¼ºåˆ¶ç»ˆæ­¢")
                        return True
                    else:
                        console.print(f"âŒ ç³»ç»Ÿå‘½ä»¤ä¹Ÿæ— æ³•ç»ˆæ­¢è¿›ç¨‹ {target_pid}")
                        console.print("ğŸ’¡ è¯·æ‰‹åŠ¨ç»ˆæ­¢è¯¥è¿›ç¨‹æˆ–ä½¿ç”¨ sudo è¿è¡Œ")
                        return False
            except Exception as e:
                console.print(f"âŒ ç³»ç»Ÿå‘½ä»¤ç»ˆæ­¢å¤±è´¥: {e}")
                console.print("ğŸ’¡ è¯·æ‰‹åŠ¨ç»ˆæ­¢è¯¥è¿›ç¨‹æˆ–ä½¿ç”¨ sudo è¿è¡Œ")
                return False
        except Exception as e:
            console.print(f"âŒ ç»ˆæ­¢è¿›ç¨‹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False
            
    except Exception as e:
        console.print(f"âŒ ç»ˆæ­¢è¿›ç¨‹æ“ä½œå¤±è´¥: {e}")
        return False


def start_pixelle_server():
    """å¯åŠ¨PixelleæœåŠ¡å™¨"""
    console.print("\nğŸš€ [bold]æ­£åœ¨å¯åŠ¨ Pixelle MCP...[/bold]")
    
    try:
        # é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡
        from dotenv import load_dotenv
        load_dotenv(override=True)
        
        port = int(settings.port)
        
        # æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨
        if check_port_in_use(port):
            process_info = get_process_using_port(port)
            if process_info:
                console.print(f"âš ï¸  [bold yellow]æ£€æµ‹åˆ°ç«¯å£ {port} å·²è¢«å ç”¨[/bold yellow]")
                console.print(f"å ç”¨è¿›ç¨‹: {process_info}")
                
                kill_service = questionary.confirm(
                    "æ˜¯å¦ç»ˆæ­¢ç°æœ‰æœåŠ¡å¹¶é‡æ–°å¯åŠ¨ï¼Ÿ",
                    default=True,
                    instruction="(Y/n)"
                ).ask()
                
                if kill_service:
                    console.print("ğŸ”„ æ­£åœ¨ç»ˆæ­¢ç°æœ‰æœåŠ¡...")
                    if kill_process_on_port(port):
                        console.print("âœ… ç°æœ‰æœåŠ¡å·²ç»ˆæ­¢")
                        import time
                        time.sleep(1)  # ç­‰å¾…ç«¯å£é‡Šæ”¾
                    else:
                        console.print("âŒ æ— æ³•ç»ˆæ­¢ç°æœ‰æœåŠ¡ï¼Œå¯åŠ¨å¯èƒ½å¤±è´¥")
                        proceed = questionary.confirm(
                            "æ˜¯å¦ä»è¦å°è¯•å¯åŠ¨ï¼Ÿ",
                            default=False,
                            instruction="(y/N)"
                        ).ask()
                        if not proceed:
                            console.print("âŒ å¯åŠ¨å·²å–æ¶ˆ")
                            return
                else:
                    console.print("âŒ å¯åŠ¨å·²å–æ¶ˆ")
                    return
            else:
                console.print(f"âš ï¸  [bold yellow]ç«¯å£ {port} è¢«å ç”¨ï¼Œä½†æ— æ³•ç¡®å®šå ç”¨è¿›ç¨‹[/bold yellow]")
                console.print("å¯åŠ¨å¯èƒ½å¤±è´¥ï¼Œå»ºè®®æ›´æ¢ç«¯å£æˆ–æ‰‹åŠ¨å¤„ç†")
        
        # å¯åŠ¨æœåŠ¡
        console.print(Panel(
            f"ğŸŒ Web ç•Œé¢: http://localhost:{settings.port}/\n"
            f"ğŸ”Œ MCP ç«¯ç‚¹: http://localhost:{settings.port}/mcp\n"
            f"ğŸ“ å·²åŠ è½½å·¥ä½œæµç›®å½•: data/custom_workflows/",
            title="ğŸ‰ Pixelle MCP æ­£åœ¨è¿è¡Œï¼",
            border_style="green"
        ))
        
        console.print("\næŒ‰ [bold]Ctrl+C[/bold] åœæ­¢æœåŠ¡\n")
        
        # å¯¼å…¥å¹¶å¯åŠ¨main
        from pixelle.main import main as start_main
        start_main()
        
    except KeyboardInterrupt:
        console.print("\nğŸ‘‹ Pixelle MCP å·²åœæ­¢")
    except Exception as e:
        console.print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")


def check_service_status():
    """æ£€æŸ¥æœåŠ¡çŠ¶æ€"""
    console.print(Panel(
        "ğŸ“‹ [bold]æ£€æŸ¥æœåŠ¡çŠ¶æ€[/bold]\n\n"
        "æ­£åœ¨æ£€æŸ¥å„é¡¹æœåŠ¡çš„è¿è¡ŒçŠ¶æ€...",
        title="æœåŠ¡çŠ¶æ€æ£€æŸ¥",
        border_style="cyan"
    ))
    
    from pixelle.settings import settings
    import requests
    
    # åˆ›å»ºçŠ¶æ€è¡¨æ ¼
    status_table = Table(title="æœåŠ¡çŠ¶æ€", show_header=True, header_style="bold cyan")
    status_table.add_column("æœåŠ¡", style="cyan", width=20)
    status_table.add_column("åœ°å€", style="yellow", width=30)
    status_table.add_column("çŠ¶æ€", width=15)
    status_table.add_column("è¯´æ˜", style="white")
    
    # æ£€æŸ¥MCPç«¯ç‚¹
    pixelle_url = f"http://{settings.host}:{settings.port}"
    mcp_status = check_url_status(f"{pixelle_url}/mcp")
    status_table.add_row(
        "MCP ç«¯ç‚¹",
        f"{pixelle_url}/mcp",
        "ğŸŸ¢ å¯ç”¨" if mcp_status else "ğŸ”´ ä¸å¯ç”¨",
        "MCPåè®®ç«¯ç‚¹" if mcp_status else "è¯·å…ˆå¯åŠ¨æœåŠ¡"
    )
    
    # æ£€æŸ¥Webç•Œé¢
    if settings.chainlit_auth_enabled:
        web_status = check_url_status(pixelle_url)
        status_table.add_row(
            "Web ç•Œé¢",
            pixelle_url,
            "ğŸŸ¢ å¯ç”¨" if web_status else "ğŸ”´ ä¸å¯ç”¨",
            "èŠå¤©ç•Œé¢" if web_status else "è¯·å…ˆå¯åŠ¨æœåŠ¡"
        )
    else:
        web_status = True  # å¦‚æœç¦ç”¨ï¼Œç®—ä½œæ­£å¸¸çŠ¶æ€
        status_table.add_row(
            "Web ç•Œé¢",
            "å·²ç¦ç”¨",
            "âšª ç¦ç”¨",
            "å·²åœ¨é…ç½®ä¸­ç¦ç”¨"
        )
    
    # æ£€æŸ¥ComfyUI
    comfyui_status = test_comfyui_connection(settings.comfyui_base_url)
    status_table.add_row(
        "ComfyUI",
        settings.comfyui_base_url,
        "ğŸŸ¢ è¿æ¥æ­£å¸¸" if comfyui_status else "ğŸ”´ è¿æ¥å¤±è´¥",
        "å·¥ä½œæµæ‰§è¡Œå¼•æ“" if comfyui_status else "è¯·æ£€æŸ¥ComfyUIæ˜¯å¦è¿è¡Œ"
    )
    
    console.print(status_table)
    
    # æ˜¾ç¤ºLLMé…ç½®çŠ¶æ€
    providers = settings.get_configured_llm_providers()
    if providers:
        console.print(f"\nğŸ¤– [bold]LLM æä¾›å•†ï¼š[/bold] {', '.join(providers)} ({len(providers)} ä¸ª)")
        models = settings.get_all_available_models()
        console.print(f"ğŸ“‹ [bold]å¯ç”¨æ¨¡å‹ï¼š[/bold] {len(models)} ä¸ª")
        console.print(f"â­ [bold]é»˜è®¤æ¨¡å‹ï¼š[/bold] {settings.chainlit_chat_default_model}")
    else:
        console.print("\nâš ï¸  [bold yellow]è­¦å‘Šï¼š[/bold yellow] æœªé…ç½®ä»»ä½•LLMæä¾›å•†")
    
    # æ€»ç»“
    total_services = 3  # MCP, Web, ComfyUI
    running_services = sum([mcp_status, web_status, comfyui_status])
    
    if running_services == total_services:
        console.print("\nâœ… [bold green]æ‰€æœ‰æœåŠ¡è¿è¡Œæ­£å¸¸ï¼[/bold green]")
    else:
        console.print(f"\nâš ï¸  [bold yellow]{running_services}/{total_services} æœåŠ¡æ­£å¸¸è¿è¡Œ[/bold yellow]")
        console.print("ğŸ’¡ å¦‚æœ‰æœåŠ¡æœªè¿è¡Œï¼Œè¯·æ£€æŸ¥é…ç½®æˆ–é‡å¯æœåŠ¡")


def check_url_status(url: str, timeout: int = 5) -> bool:
    """æ£€æŸ¥URLæ˜¯å¦å¯è®¿é—®"""
    try:
        response = requests.get(url, timeout=timeout)
        return response.status_code == 200
    except:
        return False


def show_help():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
    console.print(Panel(
        "â“ [bold]è·å–å¸®åŠ©[/bold]\n\n"
        "æ­£åœ¨æ‰“å¼€ Pixelle MCP GitHub ä¸»é¡µ...",
        title="å¸®åŠ©",
        border_style="blue"
    ))
    
    import webbrowser
    github_url = "https://github.com/AIDC-AI/Pixelle-MCP"
    
    try:
        webbrowser.open(github_url)
        console.print(f"ğŸŒ å·²åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€: {github_url}")
    except Exception as e:
        console.print(f"âŒ æ— æ³•è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨: {e}")
        console.print(f"ğŸ“‹ è¯·æ‰‹åŠ¨è®¿é—®: {github_url}")
    
    console.print("\nğŸ“š å…¶ä»–å¸®åŠ©èµ„æº:")
    console.print("â€¢ ğŸ› é—®é¢˜åé¦ˆ: https://github.com/AIDC-AI/Pixelle-MCP/issues")
    console.print("â€¢ ğŸ’¬ ç¤¾åŒºè®¨è®º: https://github.com/AIDC-AI/Pixelle-MCP#-community")


if __name__ == "__main__":
    main()
